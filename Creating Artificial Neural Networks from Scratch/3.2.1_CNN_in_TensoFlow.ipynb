{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "feJbGGIm7gMG"
   },
   "source": [
    " Build CNN model using TensorFlow for MNIST problem"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "AsW0S3vHI5MP"
   },
   "outputs": [],
   "source": [
    "# importing the libraries\n",
    "import tensorflow as tf\n",
    "\n",
    "from tensorflow.keras import datasets, layers, models\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8x65sciN7qWO"
   },
   "source": [
    "check the version of TensorFlow "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ggZCRA365tll",
    "outputId": "5a35a82d-9adc-4707-d089-c13d6d5ab46e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.5.0\n"
     ]
    }
   ],
   "source": [
    "# version of tensorflow\n",
    "print(tf.__version__)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "yt_VewbS7t1m"
   },
   "source": [
    "Load the MNIST dataset using the datasets class of tensorflow.keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "O7ZNq2zd5xuy",
    "outputId": "082ad1a2-a8f0-4f18-b5da-e37642bec1ec"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/mnist.npz\n",
      "11493376/11490434 [==============================] - 0s 0us/step\n"
     ]
    }
   ],
   "source": [
    "(train_images, train_labels), (test_images, test_labels) = datasets.mnist.load_data(path='mnist.npz')\n",
    "# Normalize pixel values to be between 0 and 1\n",
    "train_images, test_images = train_images / 255.0, test_images / 255.0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7b9KriyD72UO"
   },
   "source": [
    "We have loaded the training as well as the test set of the MNIST dataset. Also, we have normalized the pixel values for both training as well as test images. Next, let’s visualize a few images from the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 578
    },
    "id": "iM9ZMacC50si",
    "outputId": "d1bac293-0255-4a0a-ab20-cac416a71135"
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x720 with 9 Axes>"
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# visualizing a few images\n",
    "plt.figure(figsize=(10,10))\n",
    "for i in range(9):\n",
    "    plt.subplot(3,3,i+1)\n",
    "    plt.xticks([])\n",
    "    plt.yticks([])\n",
    "    plt.grid(False)\n",
    "    plt.imshow(train_images[i], cmap='gray')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "v3DFlskG784O"
   },
   "source": [
    "Subsequently, this is how our dataset looks like. We have images of handwritten digits. Let’s also look at the shapes of the training and test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "eiG5vaUV54zq",
    "outputId": "65448b28-9055-4a55-82a9-09b93e608609"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(((60000, 28, 28), (60000,)), ((10000, 28, 28), (10000,)))"
      ]
     },
     "execution_count": 5,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# shape of the training and test set\n",
    "(train_images.shape, train_labels.shape), (test_images.shape, test_labels.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "a0cEoSUw8B2n"
   },
   "source": [
    "We have 60,000 images of shape 28 by 28 in the training set and 10,000 images of the same shape in the test set. Next, we will resize the shape of images and one-hot encode the target variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "SB0EN0q66CL7"
   },
   "outputs": [],
   "source": [
    "# reshaping the images\n",
    "train_images = train_images.reshape((60000, 28, 28, 1))\n",
    "test_images = test_images.reshape((10000, 28, 28, 1))\n",
    "\n",
    "# one hot encoding the target variable\n",
    "train_labels = to_categorical(train_labels)\n",
    "test_labels = to_categorical(test_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Q7meROU28NY-"
   },
   "source": [
    "### Defining Model Architecture"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "kqwzhPh08K1e"
   },
   "source": [
    "Now, we will define the architecture of our model. So, our model will have 2 convolutional layers, with a combination of max-pooling layers, then we will have a flatten layer and finally a dense layer with 10 neurons since we have 10 classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "nSUmghJ06FHJ"
   },
   "outputs": [],
   "source": [
    "# defining the model architecture\n",
    "model = models.Sequential()\n",
    "model.add(layers.Conv2D(4, (3, 3), activation='relu', input_shape=(28, 28, 1)))\n",
    "model.add(layers.MaxPooling2D((2, 2), strides=2))\n",
    "model.add(layers.Conv2D(4, (3, 3), activation='relu'))\n",
    "model.add(layers.MaxPooling2D((2, 2), strides=2))\n",
    "model.add(layers.Flatten())\n",
    "model.add(layers.Dense(10, activation='softmax'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "eZhSZIkX8aBm"
   },
   "source": [
    "Quickly look at the summary of the model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "mKxmiCiu6JPp",
    "outputId": "5f54c312-baeb-424d-c6ea-539cb9486e2e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d (Conv2D)              (None, 26, 26, 4)         40        \n",
      "_________________________________________________________________\n",
      "max_pooling2d (MaxPooling2D) (None, 13, 13, 4)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_1 (Conv2D)            (None, 11, 11, 4)         148       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 5, 5, 4)           0         \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 100)               0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 10)                1010      \n",
      "=================================================================\n",
      "Total params: 1,198\n",
      "Trainable params: 1,198\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# summary of the model\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "DF7nVCH_8iOW"
   },
   "source": [
    "To summarize, we have 2 convolutional layers, 2 max-pooling layers, a flatten layer, and a dense layer. The total number of parameters in the model is 1,198. Now that our model is ready, we will compile it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "7V7vDtTU6LoR"
   },
   "outputs": [],
   "source": [
    "# compiling the model\n",
    "model.compile(optimizer='adam',\n",
    "              loss='categorical_crossentropy',\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "R0lJRdoi8oPO"
   },
   "source": [
    "We are using Adam optimizer, and you can change it as well. The loss function is set to be as categorical cross-entropy since we are solving a multi-class classification problem and the metric is accuracy. Now let’s train our model for 10 epochs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "-2Lrq-JF6Ob7",
    "outputId": "d373b93e-1c35-41d8-c6ec-e53c12f39a8c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "1875/1875 [==============================] - 21s 11ms/step - loss: 0.4075 - accuracy: 0.8759 - val_loss: 0.1861 - val_accuracy: 0.9425\n",
      "Epoch 2/10\n",
      "1875/1875 [==============================] - 20s 11ms/step - loss: 0.1757 - accuracy: 0.9464 - val_loss: 0.1290 - val_accuracy: 0.9612\n",
      "Epoch 3/10\n",
      "1875/1875 [==============================] - 21s 11ms/step - loss: 0.1420 - accuracy: 0.9571 - val_loss: 0.1140 - val_accuracy: 0.9643\n",
      "Epoch 4/10\n",
      "1875/1875 [==============================] - 21s 11ms/step - loss: 0.1260 - accuracy: 0.9617 - val_loss: 0.1014 - val_accuracy: 0.9681\n",
      "Epoch 5/10\n",
      "1875/1875 [==============================] - 21s 11ms/step - loss: 0.1161 - accuracy: 0.9641 - val_loss: 0.0991 - val_accuracy: 0.9676\n",
      "Epoch 6/10\n",
      "1875/1875 [==============================] - 21s 11ms/step - loss: 0.1102 - accuracy: 0.9664 - val_loss: 0.0929 - val_accuracy: 0.9705\n",
      "Epoch 7/10\n",
      "1875/1875 [==============================] - 20s 11ms/step - loss: 0.1043 - accuracy: 0.9679 - val_loss: 0.0916 - val_accuracy: 0.9719\n",
      "Epoch 8/10\n",
      "1875/1875 [==============================] - 21s 11ms/step - loss: 0.1017 - accuracy: 0.9686 - val_loss: 0.0936 - val_accuracy: 0.9716\n",
      "Epoch 9/10\n",
      "1875/1875 [==============================] - 21s 11ms/step - loss: 0.0978 - accuracy: 0.9705 - val_loss: 0.0868 - val_accuracy: 0.9726\n",
      "Epoch 10/10\n",
      "1875/1875 [==============================] - 21s 11ms/step - loss: 0.0940 - accuracy: 0.9711 - val_loss: 0.0866 - val_accuracy: 0.9725\n"
     ]
    }
   ],
   "source": [
    "# training the model\n",
    "history = model.fit(train_images, train_labels, epochs=10, validation_data=(test_images, test_labels))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9ppW6kOs7TIW"
   },
   "source": [
    "To summarize, initially, the training loss was about 0.40 and after 10 epochs, the training loss reduced to 0.09. The training and validation accuracies after 10 epochs are 97.11% and 97.25% respectively."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "hGoIXG426Q2h"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "name": "CNN in TensoFlow.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
